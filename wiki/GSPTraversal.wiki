#summary Understanding SharePoint Connector Traversal

This section will cover the following points in terms of the SharePoint connector Traversal: 

 * Glossary 
 * Discover all site collections, sites, lists, folders, attachments given the crawl URL 
 * Applying inclusion/exclusion patterns for the discovered URLs 
 * Adding/Modifying appropriate entries in Sharepoint_state.xml file 
 * Fetching metadata for the documents and applying the included, excluded metadata list rules 
 * Preparing the document list to be sent to the Connector Manager 
 * Sending individual documents to Connector Manager 
 * CheckPointing in SharePoint Connector 
 * Details specific to content feed
 * How does connector handle the case when the number of site collection is quite large and the numbers of update are very few? 
 * Impact of batch hint and traversal batch timeout on connector traversal 
 

= Glossary =

*Connector State:* The in-memory state information that connector maintains. A snapshot of this can be seen in the state file Sharepoint_state.xml

*Traversal Cycle:* One complete Scan of all the SharePoint sites and lists known till the time have been done and there are no more documents to be sent. A complete traversal cycle is said to be complete if it satisfies all the following conditions
 
 1. All the sites and lists which are discovered till the last crawl cycle and are there in the connector state got crawled and there are no more documents to be discovered from any of them.

 2. No new intermediate sites have been discovered while crawling the known sites and lists.

*Batch Traversal:* A traversal initiated to get BatchHint no. of documents. Batch traversals are returned when either of the following conditions get satisfied:

 1. Connector has discovered at least (2*BatchHint) no. of documents
 
 2. Connector has visited all the sites and lists which are known to be existent and are there in the connector state


=Discover all site collections, sites, lists, folders, attachments given the crawl URL=
 
Connector starts its traversal from the Crawl URL specified on the configuration page. The entire sites and lists discovered by the connector are stored in the connector state along with the last-crawled-site and last-crawled-list information. From the next batch traversals, connector picks the site URL to start crawling from the connector state itself. When a complete traversal cycle is completed, last-crawled-site and last-crawled-list info is reset and in the next batch traversal again starts from the Crawl URL specified on the configuration page.

The completion of a traversal cycle is more conceptual and this info is maintained by the connector by resetting the last-crawled-site and last-crawled-list. As far as the connector is concerned, it always runs a batch traversal.

 
The site URL that has been picked is processed for lists, child sites, link sites and Site Discovery sites. All discovered site URLs in a batch traversal are collected in a local store and gets updated into the connector state. These newly discovered sites are crawled in the next batch traversal(s). Each discovered list is crawled for documents. Discovery of documents are done per list and their sequence and checkpoint related information are also maintained at list level. All the discovered documents are stored in the crawl queue of the list. If the current list is able to contain attachments, connector tries to get attachments for all the discovered List Items. At the end of a list, connector constructs an extra document for the list itself which will be sent to the GSA along with other documents corresponding to the list items.

At the end of a complete traversal cycle, connector checks for those sites and lists which were discovered sometime in past but is now un-available. All such sites and lists are deleted from the connector state.

Every time a new traversal cycle is initiated from the top level site URL (that means, last batch traversal was a complete traversal cycle leaving no more documents to be discovered and sent), connector also discovers some extra sites which includes MySites, Personal sites and those sites which are returned by Google Services installed on the SharePoint server.
 
In every batch traversal, connector crawls only those sites which are there in the connector state. Any new site discovered in the current batch traversal is a candidate for crawling in future traversals.


Since, each traversal request initiated by the Connector Manager returns only when either (2*BatchHint) no. of documents are discovered or all the sites and lists are visited, this can be very time consuming when the no. of sites and lists are very large but the no. of documents added/updated are less. Such time delays are likely to occur more frequently in case of incremental crawl when the frequency of change in content is comparatively less.
 
Let's say for example, there are a total of 500 sites in the connector state that is being crawled by the connector; the BatchHint for the current crawl cycle is 50 and, no. of document updates are only 10. Now in such case, connector will not return as soon as it discovers those ten document changes. Rather, it'll try visiting each of those 500 site URLs before returning. Hence, user should be patient till the time connector confirms that there are only ten changes and no other documents in other sites have been changed. Depending on the turnaround time taken while a single web service call and the amount of processing connector has to do, this user waiting time can vary.
 
This delay is a necessary evil for the connector because it needs to scan every site and list before returning the final list of documents that have changed or updated. There has been proposal to introduce timeouts based returns from the traversals in future release of connectors.
 

=Applying inclusion/exclusion patterns for the discovered URLs=
 
All the URLs discovered by connector are checked against the included/excluded URL patterns specified by the user during configuration. Following are a few well known reasons for URL exclusion:
 1. URL does not match any of the specified included URL patterns
 2. URL matches any of the pattern specified under excluded URL patterns
 3. URL points to page whose content can not be downloaded because of some reason. This applies only in case of content feed
 4. URL points to a SharePoint 2003 site and the FeedType being used is content
 5. SharePoint version can not be determined from the given site URL


=Adding/Modifying appropriate entries in Sharepoint_state.xml file=
 
Connector always remembers its progress with the help of connector state. A snapshot of this state is stored in Sharepoint_state.xml every time a set of documents is sent to the connector manager and checkpoint is called. If the connector is stopped and restarted after sometime, this state file has all the required information for the connector to continue its traversal from the point where it had stopped last time. As long as the connector is running, it does not bother to read this file and rather uses the in-memory representation of the connector state info. The connector restart is one case when the state file is read by the connector. Technically, every time a new instance of SharePoint Traversal manager is created, connector reads this file to construct an in-memory connector state. For a complete description of the structure of state file, refer to https://sites.google.com/a/google.com/google-persistent-team-site/Home/sharepoint-connector/state-file-design-gsp2
 
From the above reference, you can get a fair idea of the structure of the state file. Changing the state file is highly discouraged. Though, in certain cases where you want to force a re-crawl of only specific sites or list, changes in the state file is required. Be extra careful while doing any change and do ensure that you are not breaking the XML node hierarchy.


*Forcing re-crawl of a site:*
 1. In the Sharepoint_state.xml, locate the WebSate node corresponding to the site that you want to re-crawl.
 {{{
<WebState .......>

    ..............
    <ListState .........>
            .....    
        <LastDocCrawled Action ............. />
    </ListState>
</WebState>
 }}}